# Awesome-Scientific-Agent

## âœ¨ Introduction

The advancement of LLM-based agents heralds a new perspective for AI for Science (AI4S), automation science research. Prominent large language models have exhibited expertise across multiple domains, prompting researchers to develop agents for the natural sciences and investigate the frontiers of scientific knowledge. Nevertheless, the divergences between the natural sciences and AI have hindered the development and advancement of scientific agents across various fields. This survey is grounded in the standardized scientific research process and elucidates the construction and evaluation of scientific agents.

* We elucidate the objective orientation of scientific research agents, which directly guides the construction for scientific agents.
* We systematically taxonomizing existing scientific research agents into three levels, with show strong hierarchical characteristics in terms of construction strategy and capability scope.
* We provides substantial and detailed answers to the questions of "how to construct a scientific agent from scratch" and "how to enhance the capabilities of existing scientific agents".

![overall](./figures/overall_short.drawio.svg)

## ğŸ“– Framework

  * [Taxonomy](#Taxonomy)
  * [Scientific Agent Construction](#scientific-agent-construction)
  * [Scientific Agent Enhancement](#scientific-agent-enhancement)
  * [Benchmarks For Scientific Agent](#benchmark-for-scientific-agent)

## ğŸ’¡Taxonomy

![overall](./figures/level.png)

### Level 1: Agent As Assistant

- **AstroLLaMAâ€‘Chat:â€¯Scalingâ€¯AstroLLaMAâ€¯withâ€¯Conversationalâ€¯andâ€¯Diverseâ€¯Datasets** â€” [![](https://img.shields.io/badge/arXiv-2024.01-red)](https://arxiv.org/abs/2401.01916)
- **BioGPT:â€¯Generativeâ€¯Preâ€‘trainedâ€¯Transformerâ€¯forâ€¯Biomedicalâ€¯Textâ€¯Generationâ€¯andâ€¯Mining** â€” [![img](https://img.shields.io/badge/arXiv-2022.10-red)](https://arxiv.org/abs/2210.10341)
- **DARWINâ€¯1.5:â€¯Largeâ€¯Languageâ€¯Modelsâ€¯asâ€¯Materialsâ€‘Scienceâ€¯Foundationâ€¯Models** â€” [![img](https://img.shields.io/badge/arXiv-2024.12-red)](https://arxiv.org/abs/2412.11970)
- **ChemBERTa:â€¯Largeâ€‘Scaleâ€¯Selfâ€‘Supervisedâ€¯Preâ€‘trainingâ€¯forâ€¯Molecularâ€¯Propertyâ€¯Prediction** â€” [![img](https://img.shields.io/badge/arXiv-2020.10-red)](https://arxiv.org/abs/2010.09885)
- **ChemAU:â€¯Harnessâ€¯theâ€¯Reasoningâ€¯ofâ€¯LLMsâ€¯inâ€¯Chemicalâ€¯Researchâ€¯withâ€¯Adaptiveâ€¯Uncertaintyâ€¯Estimation** â€” [![img](https://img.shields.io/badge/arXiv-2025.06-red)](https://arxiv.org/abs/2506.01116)
- **ChemDFM:â€¯Aâ€¯Largeâ€¯Languageâ€¯Foundationâ€¯Modelâ€¯forâ€¯Chemistry** â€” [![img](https://img.shields.io/badge/arXiv-2024.01-red)](https://arxiv.org/abs/2401.14818)
- **LlaSMol:â€¯Advancingâ€¯Largeâ€¯Languageâ€¯Modelsâ€¯forâ€¯Chemistryâ€¯withâ€¯aâ€¯Largeâ€‘Scale,â€¯Comprehensive,â€¯Highâ€‘Qualityâ€¯Instructionâ€¯Tuningâ€¯Dataset** â€” [![img](https://img.shields.io/badge/arXiv-2024.02-red)](https://arxiv.org/abs/2402.09391)
- **InstructMol:â€¯Multiâ€‘modalâ€¯Integrationâ€¯forâ€¯Buildingâ€¯aâ€¯Versatileâ€¯andâ€¯Reliableâ€¯Molecularâ€¯Assistantâ€¯inâ€¯Drugâ€¯Discovery** â€” [![img](https://img.shields.io/badge/arXiv-2023.11-red)](https://arxiv.org/abs/2311.16208)
- **ether0:â€¯Aâ€¯Scientificâ€¯Reasoningâ€¯Modelâ€¯forâ€¯Chemistry** â€” [![img](https://img.shields.io/badge/arXiv-2025.06-red)](https://arxiv.org/abs/2506.17238)
- **Leveragingâ€¯Largeâ€¯Languageâ€¯Modelsâ€¯forâ€¯Predictiveâ€¯Chemistry** â€” [![img](https://img.shields.io/badge/Nature-2024.02-blue)](https://www.nature.com/articles/s42256-023-00788-1) 
- **Multiâ€‘modalâ€¯Moleculeâ€¯Structureâ€“Textâ€¯Modelâ€¯forâ€¯Textâ€‘basedâ€¯Retrievalâ€¯andâ€¯Editing** â€” [![img](https://img.shields.io/badge/Nature-2023.12-blue)](https://www.nature.com/articles/s42256-023-00759-6)
- **ClimateGPT:â€¯Towardsâ€¯AIâ€¯Synthesizingâ€¯Interdisciplinaryâ€¯Researchâ€¯onâ€¯Climateâ€¯Change** â€” [![img](https://img.shields.io/badge/arXiv-2024.01-red)](https://arxiv.org/abs/2401.09646)
- **Sparksâ€¯ofâ€¯Science:â€¯Hypothesisâ€¯Generationâ€¯Usingâ€¯Structuredâ€¯Paperâ€¯Data** â€” [![img](https://img.shields.io/badge/arXiv-2025.04-red)](https://arxiv.org/abs/2504.12976)
- **DeepSeekâ€‘Proverâ€‘V2:â€¯Advancingâ€¯Formalâ€¯Mathematicalâ€¯Reasoningâ€¯viaâ€¯Reinforcementâ€¯Learningâ€¯forâ€¯Subgoalâ€¯Decomposition** â€” [![img](https://img.shields.io/badge/arXiv-2025.04-red)](https://arxiv.org/abs/2504.21801)
- **BiMediX:â€¯Bilingualâ€¯Medicalâ€¯Mixtureâ€¯ofâ€¯Expertsâ€¯LLM** â€” [![img](https://img.shields.io/badge/arXiv-2024.02-red)](https://arxiv.org/abs/2402.13253)
- **ChatDoctor:â€¯Aâ€¯Medicalâ€¯Chatâ€¯Modelâ€¯Fineâ€‘tunedâ€¯onâ€¯aâ€¯Largeâ€¯Languageâ€¯Modelâ€¯(LLAMA)â€¯Usingâ€¯Medicalâ€¯Domainâ€¯Knowledge** â€” [![img](https://img.shields.io/badge/arXiv-2023.03-red)](https://arxiv.org/abs/2303.14070)
- **AgentMD:â€¯Empoweringâ€¯Languageâ€¯Agentsâ€¯forâ€¯Riskâ€¯Predictionâ€¯withâ€¯Largeâ€‘Scaleâ€¯Clinicalâ€¯Toolâ€¯Learning** â€” [![img](https://img.shields.io/badge/arXiv-2024.02-red)](https://arxiv.org/abs/2402.13225)
- **MedAlpaca:â€¯Anâ€¯Openâ€‘Sourceâ€¯Collectionâ€¯ofâ€¯Medicalâ€¯Conversationalâ€¯AIâ€¯Modelsâ€¯andâ€¯Trainingâ€¯Data** â€” [![img](https://img.shields.io/badge/arXiv-2023.04-red)](https://arxiv.org/abs/2304.08247)
- **DrugGenâ€¯Enhancesâ€¯Drugâ€¯Discoveryâ€¯withâ€¯Largeâ€¯Languageâ€¯Modelsâ€¯andâ€¯Reinforcementâ€¯Learning** â€” [![img](https://img.shields.io/badge/Nature-2025.04-blue)](https://www.nature.com/articles/s41598-025-98629-1) 
- **LLMâ€‘SR:â€¯Scientificâ€¯Equationâ€¯Discoveryâ€¯viaâ€¯Programmingâ€¯withâ€¯Largeâ€¯Languageâ€¯Models** â€” [![img](https://img.shields.io/badge/arXiv-2024.04-red)](https://arxiv.org/abs/2404.18400)
- **LitLLM:â€¯Aâ€¯Toolkitâ€¯forâ€¯Scientificâ€¯Literatureâ€¯Review** â€” [![img](https://img.shields.io/badge/arXiv-2024.02-red)](https://arxiv.org/abs/2402.01788)
- **SciBERT:â€¯Aâ€¯Pretrainedâ€¯Languageâ€¯Modelâ€¯forâ€¯Scientificâ€¯Text** â€” [![img](https://img.shields.io/badge/arXiv-2019.03-red)](https://arxiv.org/abs/1903.10676)
- **SciMON:â€¯Scientificâ€¯Inspirationâ€¯Machinesâ€¯Optimizedâ€¯forâ€¯Novelty** â€” [![](https://img.shields.io/badge/arXiv-2023.05-red)](https://arxiv.org/abs/2305.14259)
- **SCITUNE:â€¯Aligningâ€¯Largeâ€¯Languageâ€¯Modelsâ€¯withâ€¯Scientificâ€¯Multimodalâ€¯Instructions** â€” [![img](https://img.shields.io/badge/arXiv-2023.07-red)](https://arxiv.org/abs/2307.01139)
- **NatureLM:â€¯Decipheringâ€¯theâ€¯Languageâ€¯ofâ€¯Natureâ€¯forâ€¯Scientificâ€¯Discovery** â€” [![img](https://img.shields.io/badge/arXiv-2025.02-red)](https://arxiv.org/abs/2502.07527)

### Level 2: Agent As Partner

- **StarWhisper Telescope:â€¯Agentâ€‘Based Observation Assistant System to Approach anâ€¯AIâ€¯Astrophysicist** â€” [![img](https://img.shields.io/badge/arXiv-2024.12-red)](https://arxiv.org/abs/2412.06412)
- **Fromâ€¯Intentionâ€¯toâ€¯Implementation:â€¯Automatingâ€¯Biomedicalâ€¯Researchâ€¯viaâ€¯LLMs** â€” [![img](https://img.shields.io/badge/arXiv-2024.12-red)](https://arxiv.org/abs/2412.09429)
- **CRISPRâ€‘GPT:â€¯Anâ€¯LLMâ€¯Agentâ€¯forâ€¯Automatedâ€¯Designâ€¯ofâ€¯Geneâ€‘Editingâ€¯Experiments** â€” [![img](https://img.shields.io/badge/arXiv-2024.04-red)](https://arxiv.org/abs/2404.18021)
- **Towardsâ€¯anâ€¯AIâ€¯Coâ€‘Scientist** â€” [![img](https://img.shields.io/badge/arXiv-2025.02-red)](https://arxiv.org/abs/2502.18864)
- **DrBioRightâ€¯2.0:â€¯Anâ€¯LLMâ€‘Poweredâ€¯Bioinformaticsâ€¯Chatbotâ€¯forâ€¯Largeâ€‘Scaleâ€¯Cancerâ€¯Functionalâ€¯Proteomicsâ€¯Analysis** â€” [![img](https://img.shields.io/badge/Nature-2025.03-blue)](https://www.nature.com/articles/s41467-025-57430-4)
- **ProtAgents:â€¯Proteinâ€¯Discoveryâ€¯viaâ€¯Largeâ€¯Languageâ€¯Modelâ€¯Multiâ€‘Agentâ€¯Collaboration** â€” [![img](https://img.shields.io/badge/arXiv-2024.02-red)](https://arxiv.org/abs/2402.04268)
- **MOOSEâ€‘Chem:â€¯Largeâ€¯Languageâ€¯Modelsâ€¯forâ€¯Rediscoveringâ€¯Unseenâ€¯Chemistryâ€¯Scientificâ€¯Hypotheses** â€” [![img](https://img.shields.io/badge/arXiv-2024.10-red)](https://arxiv.org/abs/2410.07076)
- **Autonomousâ€¯Chemicalâ€¯Researchâ€¯withâ€¯Largeâ€¯Languageâ€¯Models** â€” [![img](https://img.shields.io/badge/Nature-2023.12-blue)](https://www.nature.com/articles/s41586-023-06792-0)
- **ChemCrow:â€¯Augmentingâ€¯Largeâ€‘Languageâ€¯Modelsâ€¯withâ€¯Chemistryâ€¯Tools** â€” [![img](https://img.shields.io/badge/arXiv-2023.04-red)](https://arxiv.org/abs/2304.05376)
- **ORGANA:â€¯Aâ€¯Roboticâ€¯Assistantâ€¯forâ€¯Automatedâ€¯Chemistryâ€¯Experimentationâ€¯andâ€¯Characterization** â€” [![img](https://img.shields.io/badge/arXiv-2024.01-red)](https://arxiv.org/abs/2401.06949)
- **xChemAgents:â€¯Agenticâ€¯AIâ€¯forâ€¯Explainableâ€¯Quantumâ€¯Chemistry** â€” [![img](https://img.shields.io/badge/arXiv-2025.05-red)](https://arxiv.org/abs/2505.20574)
- **ChemAgent:â€¯Selfâ€‘Updatingâ€¯Memoriesâ€¯inâ€¯Largeâ€¯Languageâ€¯Modelsâ€¯Improvesâ€¯Chemicalâ€¯Reasoning** â€” [![img](https://img.shields.io/badge/arXiv-2025.01-red)](https://arxiv.org/abs/2501.06590)
- **Largeâ€¯Languageâ€¯Modelsâ€¯toâ€¯Accelerateâ€¯Organicâ€¯Chemistryâ€¯Synthesis** â€” [![img](https://img.shields.io/badge/arXiv-2025.04-red)](https://arxiv.org/abs/2504.18340)
- **MyCrunchGPT:â€¯Aâ€¯ChatGPTâ€‘Assistedâ€¯Frameworkâ€¯forâ€¯Scientificâ€¯Machineâ€¯Learning** â€” [![img](https://img.shields.io/badge/arXiv-2023.06-red)](https://arxiv.org/abs/2306.15551)
- **MetaOpenFoam:â€¯Anâ€¯LLMâ€‘Basedâ€¯Multiâ€‘Agentâ€¯Frameworkâ€¯forâ€¯CFD** â€” [![img](https://img.shields.io/badge/arXiv-2024.07-red)](https://arxiv.org/abs/2407.21320)
- **FoamAgent:â€¯Towardsâ€¯Automatedâ€¯Intelligentâ€¯CFDâ€¯Workflows** â€” [![img](https://img.shields.io/badge/arXiv-2025.05-red)](https://arxiv.org/abs/2505.04997)
- **AIâ€‘Researcher:â€¯Autonomousâ€¯Scientificâ€¯Innovation** â€” [![img](https://img.shields.io/badge/arXiv-2025.05-red)](https://arxiv.org/abs/2505.18705)
- **Jupybara:â€¯Operationalizingâ€¯aâ€¯Designâ€¯Spaceâ€¯forâ€¯Actionableâ€¯Dataâ€¯Analysisâ€¯andâ€¯Storytellingâ€¯withâ€¯LLMs** â€” [![img](https://img.shields.io/badge/arXiv-2025.01-red)](https://arxiv.org/abs/2501.16661)
- **FlowAgent:â€¯Achievingâ€¯Complianceâ€¯andâ€¯Flexibilityâ€¯forâ€¯Workflowâ€¯Agents** â€” [![img](https://img.shields.io/badge/arXiv-2025.02-red)](https://arxiv.org/abs/2502.14345)
- **Theâ€¯AIâ€¯Scientist:â€¯Towardsâ€¯Fullyâ€¯Automatedâ€¯Openâ€‘Endedâ€¯Scientificâ€¯Discovery** â€” [![img](https://img.shields.io/badge/arXiv-2024.08-red)](https://arxiv.org/abs/2408.06292)
- **GeoGPT:â€¯Understandingâ€¯andâ€¯Processingâ€¯Geospatialâ€¯Tasksâ€¯throughâ€¯anâ€¯Autonomousâ€¯GPT** â€” [![img](https://img.shields.io/badge/arXiv-2023.07-red)](https://arxiv.org/abs/2307.07930)
- **PaperQA:â€¯Retrievalâ€‘Augmentedâ€¯Generativeâ€¯Agentâ€¯forâ€¯Scientificâ€¯Research** â€” [![img](https://img.shields.io/badge/arXiv-2023.12-red)](https://arxiv.org/abs/2312.07559)
- **ChatCite:â€¯LLMâ€¯Agentâ€¯withâ€¯Humanâ€¯Workflowâ€¯Guidanceâ€¯forâ€¯Comparativeâ€¯Literatureâ€¯Summary** â€” [![img](https://img.shields.io/badge/arXiv-2024.03-red)](https://arxiv.org/abs/2403.02574)
- **PiFlow:â€¯Principleâ€‘Awareâ€¯Scientificâ€¯Discoveryâ€¯withâ€¯Multiâ€‘Agentâ€¯Collaboration** â€” [![img](https://img.shields.io/badge/arXiv-2025.05-red)](https://arxiv.org/abs/2505.15047)
- **Aviary:â€¯Trainingâ€¯Languageâ€¯Agentsâ€¯onâ€¯Challengingâ€¯Scientificâ€¯Tasks** â€” [![img](https://img.shields.io/badge/arXiv-2024.12-red)](https://arxiv.org/abs/2412.21154)
- **Anâ€¯Autonomousâ€¯Laboratoryâ€¯forâ€¯theâ€¯Acceleratedâ€¯Synthesisâ€¯ofâ€¯Novelâ€¯Materials** â€” [![img](https://img.shields.io/badge/Nature-2023.12-blue)](https://pubmed.ncbi.nlm.nih.gov/38030721/)
- **Constructionâ€¯ofâ€¯aâ€¯Knowledgeâ€¯Graphâ€¯forâ€¯Frameworkâ€¯Materialâ€¯Enabledâ€¯byâ€¯Largeâ€¯Languageâ€¯Modelsâ€¯andâ€¯Itsâ€¯Application** â€” [![img](https://img.shields.io/badge/npjCM-2025.02-blue)](https://www.nature.com/articles/s41524-025-01540-6)
- **MultiCrossModalâ€¯Automatedâ€¯Agentâ€¯forâ€¯Integratingâ€¯Diverseâ€¯Materialsâ€¯Scienceâ€¯Data** â€” [![img](https://img.shields.io/badge/arXiv-2025.05-red)](https://arxiv.org/abs/2505.15132)
- **LLMatDesign:â€¯Autonomousâ€¯Materialsâ€¯Discoveryâ€¯withâ€¯Largeâ€¯Languageâ€¯Models** â€” [![img](https://img.shields.io/badge/arXiv-2024.06-red)](https://arxiv.org/abs/2406.13163)
- **Honeycomb:â€¯Aâ€¯Flexibleâ€¯LLMâ€‘Basedâ€¯Agentâ€¯Systemâ€¯forâ€¯Materialsâ€¯Science** â€” [![img](https://img.shields.io/badge/arXiv-2024.09-red)](https://arxiv.org/abs/2409.00135)
- **DrugAgent:â€¯Automatingâ€¯AIâ€‘Aidedâ€¯Drugâ€¯Discoveryâ€¯Programmingâ€¯throughâ€¯LLMâ€¯Multiâ€‘Agentâ€¯Collaboration** â€” [![img](https://img.shields.io/badge/arXiv-2024.11-red)](https://arxiv.org/abs/2411.15692)
- **Towardâ€¯aâ€¯Teamâ€¯ofâ€¯AIâ€‘Madeâ€¯Scientistsâ€¯forâ€¯Scientificâ€¯Discoveryâ€¯fromâ€¯Geneâ€¯Expressionâ€¯Data** â€” [![img](https://img.shields.io/badge/arXiv-2024.02-red)](https://arxiv.org/abs/2402.12391)
- **MedAgents:â€¯Largeâ€¯Languageâ€¯Modelsâ€¯asâ€¯Collaboratorsâ€¯forâ€¯Zeroâ€‘Shotâ€¯Medicalâ€¯Reasoning** â€” [![img](https://img.shields.io/badge/arXiv-2023.11-red)](https://arxiv.org/abs/2311.10537)
- **Automationâ€¯ofâ€¯Systematicâ€¯Reviewsâ€¯withâ€¯Largeâ€¯Languageâ€¯Models** â€” [![img](https://img.shields.io/badge/medRxiv-2025.06-blue)](https://www.medrxiv.org/content/10.1101/2025.06.13.25329541v2)
- **MRAgent:â€¯Anâ€¯LLMâ€‘Basedâ€¯Automatedâ€¯Agentâ€¯forâ€¯Causalâ€¯Knowledgeâ€¯Discoveryâ€¯inâ€¯Diseaseâ€¯viaâ€¯Mendelianâ€¯Randomization** â€” [![img](https://img.shields.io/badge/BriefBioinf-2025.03-blue)](https://academic.oup.com/bib/article/26/2/bbaf140/8107848)
- **GeneGPT:â€¯Augmentingâ€¯Largeâ€¯Languageâ€¯Modelsâ€¯withâ€¯Domainâ€¯Toolsâ€¯forâ€¯Improvedâ€¯Accessâ€¯toâ€¯Biomedicalâ€¯Information** â€” [![img](https://img.shields.io/badge/arXiv-2023.04-red)](https://arxiv.org/abs/2304.09667)

### Level 3: Agent As Avatar

- **CycleResearcher:â€¯Improvingâ€¯Automatedâ€¯Researchâ€¯viaâ€¯Automatedâ€¯Review** â€” [![img](https://img.shields.io/badge/arXiv-2024.11-red)](https://arxiv.org/abs/2411.00816)
- **Theâ€¯AIâ€¯Scientistâ€‘v2:â€¯Workshopâ€‘Levelâ€¯Automatedâ€¯Scientificâ€¯Discoveryâ€¯viaâ€¯Agenticâ€¯Treeâ€¯Search** â€” [![img](https://img.shields.io/badge/arXiv-2025.04-red)](https://arxiv.org/abs/2504.08066)
- **AgentRxiv:â€¯Towardsâ€¯Collaborativeâ€¯Autonomousâ€¯Research** â€” [![img](https://img.shields.io/badge/arXiv-2025.03-red)](https://arxiv.org/abs/2503.18102)
- **Agentâ€¯Laboratory:â€¯Usingâ€¯LLMâ€¯Agentsâ€¯asâ€¯Researchâ€¯Assistants** â€” [![img](https://img.shields.io/badge/arXiv-2025.01-red)](https://arxiv.org/abs/2501.04227)
- **BiOMNI:â€¯Aâ€¯Generalâ€‘Purposeâ€¯Biomedicalâ€¯AIâ€¯Agent** â€” [![img](https://img.shields.io/badge/bioRxiv-2025.05-blue)](https://www.biorxiv.org/content/10.1101/2025.05.30.656746v1)
- **OriGene:â€¯Aâ€¯Selfâ€‘Evolvingâ€¯Virtualâ€¯Diseaseâ€¯Biologistâ€¯Automatingâ€¯Therapeuticâ€¯Targetâ€¯Discovery** â€” [![img](https://img.shields.io/badge/bioRxiv-2025.06-blue)](https://www.biorxiv.org/content/10.1101/2025.06.03.657658v1)
- **CellVoyager:â€¯AIâ€¯CompBioâ€¯Agentâ€¯Generatesâ€¯Newâ€¯Insightsâ€¯byâ€¯Autonomouslyâ€¯Analyzingâ€¯Biologicalâ€¯Data** â€” [![img](https://img.shields.io/badge/bioRxiv-2025.06-blue)](https://www.biorxiv.org/content/10.1101/2025.06.03.657517v1)
- **Sparks:â€¯Multiâ€‘Agentâ€¯Artificialâ€¯Intelligenceâ€¯Modelâ€¯Discoversâ€¯Proteinâ€¯Designâ€¯Principles** â€” [![img](https://img.shields.io/badge/arXiv-2025.04-red)](https://arxiv.org/abs/2504.19017)
- **AlphaEvolve:â€¯Aâ€¯Codingâ€¯Agentâ€¯forâ€¯Scientificâ€¯andâ€¯Algorithmicâ€¯Discovery** â€” [![img](https://img.shields.io/badge/arXiv-2025.06-red)](https://arxiv.org/abs/2506.13131)
- **Robin:â€¯Aâ€¯Multiâ€‘Agentâ€¯Systemâ€¯forâ€¯Automatingâ€¯Scientificâ€¯Discovery** â€” [![img](https://img.shields.io/badge/arXiv-2025.05-red)](https://arxiv.org/abs/2505.13400)

## âœˆï¸ Scientific Agent Construction

![overall](./figures/section3.drawio.svg)
- **PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization** â€” [![img](https://img.shields.io/badge/arXiv-2023.10-red)](https://arxiv.org/abs/2310.16427) 
- **Context Engineering: A Practical Handbook for Context Design, Orchestration, and Optimization** â€” [![img](https://img.shields.io/badge/GitHub-Context--Engineering-green)](https://github.com/davidkimai/Context-Engineering)  

- **Verl: Volcano Engine Reinforcement Learning for Large Language Models** â€” [![img](https://img.shields.io/badge/GitHub-Verl-green)](https://github.com/zjunlp/Verl)  
- **GraphRAG: A Modular Graph-Based Retrieval-Augmented Generation (RAG) System** â€” [![img](https://img.shields.io/badge/arXiv-2023.11-red)](https://arxiv.org/abs/2311.06753)  
- **ChemCrow: Augmenting Largeâ€‘Language Models with Chemistry Tools** â€” [![img](https://img.shields.io/badge/arXiv-2023.04-red)](https://arxiv.org/abs/2304.05376)  
- **Virtual Lab: AI Agents Design New SARS-CoV-2 Nanobodies with Experimental Validation** â€” [![img](https://img.shields.io/badge/arXiv-2024.11-red)](https://www.biorxiv.org/content/10.1101/2024.11.11.623004v1)  
- **OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning** â€” [![img](https://img.shields.io/badge/arXiv-2025.02-red)](https://arxiv.org/abs/2502.11271)  
- **FoamAgent: Towards Automated Intelligent CFD Workflows** â€” [![img](https://img.shields.io/badge/arXiv-2025.05-red)](https://arxiv.org/abs/2505.04997)  
- **MetaOpenFoam: An LLM-Based Multi-Agent Framework for CFD** â€” [![img](https://img.shields.io/badge/arXiv-2024.07-red)](https://arxiv.org/abs/2407.21320)  
- **AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts** â€” [![img](https://img.shields.io/badge/EMNLP-2020-red)](https://arxiv.org/abs/2010.15980)  
- **InstructBio: Instruction Tuning for Biomedical LLMs** â€” [![img](https://img.shields.io/badge/arXiv-2024.02-red)](https://arxiv.org/abs/2310.19975)  
- **LangChain: Building Applications with LLMs through Composability** â€” [![img](https://img.shields.io/badge/GitHub-LangChain-green)](https://github.com/langchain-ai/langchain)  
- **LightRAG: Simple and Fast Retrievalâ€‘Augmented Generation** â€” [![img](https://img.shields.io/badge/arXiv-2024.10-red)](https://arxiv.org/abs/2410.05779)  
- **SciTUNE: Aligning Large Language Models with Scientific Multimodal Instructions** â€” [![img](https://img.shields.io/badge/arXiv-2023.07-red)](https://arxiv.org/abs/2307.01139)

- **ClimateGPT: Towards AI Synthesizing Interdisciplinary Research on Climate Change** â€” [![img](https://img.shields.io/badge/arXiv-2024.01-red)](https://arxiv.org/abs/2401.09646)

- **SciMON: Scientific Inspiration Machines Optimized for Novelty** â€” [![img](https://img.shields.io/badge/arXiv-2023.05-red)](https://arxiv.org/abs/2305.14259)

- **TAIS: Gene Expression Agent with LLMs** â€” [![img](https://img.shields.io/badge/arXiv-2025.03-red)](https://arxiv.org/abs/2503.02973)

- **StarWhisper Telescope: Agentâ€‘Based Observation Assistant System to Approach anâ€¯AIâ€¯Astrophysicist** â€” [![img](https://img.shields.io/badge/arXiv-2024.12-red)](https://arxiv.org/abs/2412.06412)

## ğŸš€ Scientific Agent Enhancement
- **MemGPT: Toward LLMs as Operating Systems** â€” [![img](https://img.shields.io/badge/arXiv-2023.10-red)](https://arxiv.org/abs/2310.08560) 
- **AFlow: Automating Agentic Workflow Generation** â€” [![img](https://img.shields.io/badge/arXiv-2023.07-red)](https://arxiv.org/abs/2410.10762)  
- **ChemAgent: Selfâ€‘Updating Memories in Large Language Models Improves Chemical Reasoning** â€” [![img](https://img.shields.io/badge/ICLR-2025-red)](https://arxiv.org/abs/2501.06590)  
- **DeepSeekâ€‘Proverâ€‘V2: Advancing Formal Mathematical Reasoning** â€” [![img](https://img.shields.io/badge/arXiv-2025.04-red)](https://arxiv.org/abs/2504.21801)  
- **LLMâ€‘SR: Scientific Equation Discovery via Programming with LLMs** â€” [![img](https://img.shields.io/badge/ICLR-2025-red)](https://arxiv.org/abs/2404.18400)  
- **Sparks: Multiâ€‘Agent Artificial Intelligence Model Discovers Protein Design Principles** â€” [![img](https://img.shields.io/badge/arXiv-2025.04-red)](https://arxiv.org/abs/2504.19017)  
- **ether0: A Scientific Reasoning Model for Chemistry** â€” [![img](https://img.shields.io/badge/arXiv-2025.06-red)](https://arxiv.org/abs/2506.17238)  
- **Robin: A Multiâ€‘Agent System for Automating Scientific Discovery** â€” [![img](https://img.shields.io/badge/arXiv-2025.05-red)](https://arxiv.org/abs/2505.13400)  
- **AgentRxiv: Towards Collaborative Autonomous Research** â€” [![img](https://img.shields.io/badge/arXiv-2025.03-red)](https://arxiv.org/abs/2503.18102)  
- **ChatGPT Research Group for Optimizing the Crystallinity of MOFs and COFs** â€” [![img](https://img.shields.io/badge/ACS-2023-red)](https://doi.org/10.1021/acscentsci.3c00765)  
- **AI Co-Scientist: Towards an AI Co-Scientist** â€” [![img](https://img.shields.io/badge/arXiv-2025.02-red)](https://arxiv.org/abs/2502.18864)  
- **ReAct: Synergizing Reasoning and Acting in Language Models** â€” [![img](https://img.shields.io/badge/arXiv-2022.10-red)](https://arxiv.org/abs/2210.03629)  
- **Reflexion: Language Agents with Verbal Reinforcement Learning** â€” [![img](https://img.shields.io/badge/NeurIPS-2023-red)](https://arxiv.org/abs/2303.11366)  
- **Selfâ€‘Refine: Iterative Selfâ€‘Improvement with Selfâ€‘Feedback** â€” [![img](https://img.shields.io/badge/arXiv-2023.06-red)](https://arxiv.org/abs/2306.11382)  

- **Selfâ€‘Consistency: Reliable Decoding for Complex Reasoning** â€” [![img](https://img.shields.io/badge/ICLR-2023-red)](https://arxiv.org/abs/2203.11171)  

- **AquilaChat: Agent with Long-Context Scratchpad Memory** â€” [![img](https://img.shields.io/badge/arXiv-2024.03-red)](https://arxiv.org/abs/2403.00220)

![overall](./figures/section4.drawio.svg)

## âš–ï¸ Benchmark For Scientific Agent
- **BioMaze: benchmark for complex biological pathway reasoning** â€” [![img](https://img.shields.io/badge/HF-BioMaze-blue)](https://huggingface.co/datasets/haitengzhao/BioMaze)  [oai_citation:0â€¡arxiv.org](https://arxiv.org/abs/2502.16660?utm_source=chatgpt.com) [oai_citation:1â€¡github.com](https://github.com/zhao-ht/BioMaze?utm_source=chatgpt.com)
- **BiokgBench: benchmark for biomedical KG factual checking** â€” [![img](https://img.shields.io/badge/GitHub-BioKGBench-green)](https://github.com/westlake-autolab/BioKGBench)  [oai_citation:2â€¡github.com](https://github.com/westlake-autolab/BioKGBench?utm_source=chatgpt.com)
- **Tomato-Chem: benchmark for chemistry hypothesis discovery** â€” [![img](https://img.shields.io/badge/GitHub-MOOSE--Chem-green)](https://github.com/ZonglinY/MOOSE-Chem)
- **SurveyBench: benchmark for CS literature survey generation** â€” [![img](https://img.shields.io/badge/GitHub-SurveyForge-green)](https://github.com/Alpha-Innovator/SurveyForge)
- **MMLUâ€‘Pro: benchmark for professional-level multidisciplinary QA** â€” [![img](https://img.shields.io/badge/HF-MMLU--Pro-blue)](https://huggingface.co/datasets/TIGER-Lab/MMLU-Pro)
- **HLE: benchmark for hard science question answering** â€” [![img](https://img.shields.io/badge/Web-lastexam.ai-blue)](https://lastexam.ai/)
- **ScienceQA: multimodal science QA benchmark** â€” [![img](https://img.shields.io/badge/Web-ScienceQA-blue)](https://scienceqa.github.io/)
- **GPQA: benchmark for hard science QA with hybrid formats** â€” [![img](https://img.shields.io/badge/HF-GPQA-blue)](https://huggingface.co/datasets/Idavidrein/gpqa/)
- **SuperGPQA: large-scale advanced science QA benchmark** â€” [![img](https://img.shields.io/badge/HF-SuperGPQA-blue)](https://huggingface.co/datasets/m-a-p/SuperGPQA)
- **CiteBench: benchmark for citation-text generation evaluation** â€” [![img](https://img.shields.io/badge/GitHub-CiteBench-green)](https://github.com/UKPLab/citebench)
- **ALCE: benchmark for automated citation generation** â€” [![img](https://img.shields.io/badge/GitHub-ALCE-green)](https://github.com/princeton-nlp/ALCE)
- **Reviewer2: benchmark for peer-review generation** â€” [![img](https://img.shields.io/badge/GitHub-Reviewer2-green)](https://github.com/ZhaolinGao/Reviewer2)
- **Scientists' First Exam: benchmark for multi-domain science knowledge probing** â€” [![img](https://img.shields.io/badge/HF-SFE-blue)](https://huggingface.co/datasets/PrismaX/SFE)
- **MRâ€‘Ben: benchmark for multipleâ€‘choice science reasoning** â€” [![img](https://img.shields.io/badge/Web-MR--Ben-blue)](https://randolph-zeng.github.io/Mr-Ben.github.io/)
- **FigureQA: benchmark for figure/chart QA tasks** â€” [![img](https://img.shields.io/badge/HF-FigureQA-blue)](https://huggingface.co/datasets/vikhyatk/figureqa)
- **SciEval: benchmark for scientific research QA evaluation** â€” [![img](https://img.shields.io/badge/HF-SciEval-blue)](https://huggingface.co/datasets/OpenDFM/SciEval)
- **MedQA: benchmark for medical exam-style QA** â€” [![img](https://img.shields.io/badge/HF-MedQA-blue)](https://huggingface.co/datasets/bigbio/med_qa)
- **LLMâ€‘SRBench: benchmark for scientific equation discovery tasks** â€” [![img](https://img.shields.io/badge/HF-LLM--SRBench-blue)](https://huggingface.co/datasets/nnheui/llm-srbench)
- **GenoTEX: benchmark for genomic data analysis generation** â€” [![img](https://img.shields.io/badge/HF-GenoTEX-blue)](https://huggingface.co/datasets/Liu-Hy/GenoTEX)
- **MLAgentBench: benchmark for ML experiment implementation** â€” [![img](https://img.shields.io/badge/GitHub-MLAgentBench-green)](https://github.com/snap-stanford/MLAgentBench)
- **PaperBench: benchmark for scientific paper replication tasks** â€” [![img](https://img.shields.io/badge/Web-PaperBench-blue)](https://openai.com/research/paperbench)
- **DSâ€‘Bench: benchmark for data science analysis tasks** â€” [![img](https://img.shields.io/badge/GitHub-DSBench-green)](https://github.com/LiqiangJing/DSBench)
- **DiscoveryWorld: benchmark for multi-step scientific experiment implementation** â€” [![img](https://img.shields.io/badge/GitHub-DiscoveryWorld-green)](https://github.com/allenai/discoveryworld)
- **SciCode: benchmark for code generation in scientific workflows** â€” [![img](https://img.shields.io/badge/GitHub-SciCode-green)](https://github.com/scicode-bench/SciCode)
- **AgentClinic: benchmark for clinical decision evaluation by agents** â€” [![img](https://img.shields.io/badge/GitHub-AgentClinic-green)](https://github.com/SamuelSchmidgall/AgentClinic)
- **SDRBench: benchmark for scientific data reduction tasks** â€” [![img](https://img.shields.io/badge/Web-SDRBench-blue)](https://sdrbench.github.io/)

## ğŸŒ Citation
